
---

# ðŸ’³ðŸš¨ Credit Card Fraud Detection System Project

## ðŸ“Œ Project Overview

Credit card fraud detection is a highly imbalanced classification problem where fraudulent transactions represent a very small fraction of all transactions, yet carry significant financial and reputational risk. This project presents an **end-to-end machine learning pipeline** for detecting fraudulent credit card transactions, with a strong emphasis on **model performance, threshold optimization, and interpretability**.

The goal is not only to build an accurate fraud detection model, but also to ensure that predictions are **transparent, explainable, and aligned with real-world decision-making**.

---

## ðŸŽ¯ Objectives

* Detect fraudulent transactions with high recall while maintaining acceptable precision
* Address severe class imbalance using appropriate modeling strategies
* Select decision thresholds based on business-aligned trade-offs
* Provide global and local explanations of model predictions using SHAP
* Produce a reproducible, portfolio-grade machine learning workflow

---

## ðŸ“‚ Dataset

* **Source:** [Kaggle Dataset Credit Card Fraud Detection](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)
* **Description:** Anonymized transaction features derived from PCA transformations, along with transaction amount and class label
* **Target Variable:**

  * `0` â†’ Legitimate transaction
  * `1` â†’ Fraudulent transaction
* **Key Challenge:** Extreme class imbalance (~0.17% fraud cases)

---

## ðŸ› ï¸ Methodology

### 1ï¸âƒ£ Data Preprocessing

* Trainâ€“test split with stratification
* Feature scaling where appropriate
* Careful handling of class imbalance

### 2ï¸âƒ£ Modeling Approaches

* **Random Forest Classifier**

  * Baseline model
  * Explored class weighting and threshold adjustment

* **LightGBM Classifier (Final Model)**

  * Gradient-boosted decision trees
  * Optimized for imbalanced classification
  * Superior recallâ€“precision trade-off

### 3ï¸âƒ£ Model Evaluation

Models were evaluated using metrics suitable for imbalanced data:

* Precision
* Recall
* F1-score
* ROC-AUC
* Precisionâ€“Recall curves

Decision thresholds were selected based on:

* Precision-constrained recall
* F1-score maximization
* Business cost considerations

---

## ðŸ§  Model Interpretability (SHAP)

To ensure transparency and trust, SHAP (SHapley Additive exPlanations) was used to interpret model predictions.

### Global Interpretability

* Feature importance analysis to identify key fraud indicators
* SHAP summary plots to understand direction and magnitude of feature effects

### Local Interpretability

* Transaction-level explanations for individual fraud cases
* Clear visualization of features pushing predictions toward fraud or legitimacy

All explanations focus on the **fraud class (class 1)** and are aligned with the final decision threshold.

---

## ðŸ† Results Summary

* LightGBM achieved strong recall on fraudulent transactions while maintaining reasonable precision
* SHAP analysis confirmed that the model relies on a consistent and interpretable set of fraud indicators
* The final system balances performance, explainability, and reproducibility

---

## ðŸ“ Project Structure

```text
â”œâ”€â”€ dataset/
â”‚   â””â”€â”€ archive.zip
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ Credit_Card_Fraud_Detection_System.ipynb
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ lgbm/
|   |     â”œâ”€â”€ lgbm_baseline.pkl
|   |     â”œâ”€â”€ lgbm_tuned.pkl
|   |     â””â”€â”€ lgbm_metadata.json
â”‚   â””â”€â”€ random_forest/
|          â”œâ”€â”€ rf_metadata.json
|          â””â”€â”€ rf_model.pkl 
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## ðŸš€ How to Run the Project

1. Clone the repository:

```bash
git clone https://github.com/SaintJeane/credit_card_fraud_detection_system_for_credit_card_transactions.git
```

2. Install dependencies:

```bash
pip install -r requirements.txt
```

3. Open the notebook:

```bash
jupyter notebook notebooks/Credit_Card_Fraud_Detection_System.ipynb
```

---

## ðŸ“¦ Tools & Technologies

* Python
* scikit-learn
* LightGBM
* SHAP
* NumPy
* pandas
* matplotlib / seaborn
* joblib

---

## ðŸ“ˆ Key Takeaways

* Imbalanced classification requires **careful metric selection**, not accuracy alone
* Decision thresholds are as important as the model itself
* Interpretability is essential for deploying fraud detection systems in practice
* Combining performance with explainability leads to more trustworthy models

---

> *This project was developed as a portfolio-grade demonstration of applied machine learning for fraud detection, with a focus on real-world constraints and interpretability.*

---
